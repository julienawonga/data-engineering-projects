# ğŸ“š README.md â€” Projet RetailFlow : Stack Data Engineering

## ğŸš€ 1. Introduction

**RetailFlow** est un projet de **Data Engineering complet** conÃ§u pour simuler le traitement, l'intÃ©gration, la transformation, et l'analyse de donnÃ©es dans le secteur du **retail (commerce de dÃ©tail)**. Ce projet illustre comment collecter, centraliser et analyser des donnÃ©es transactionnelles et des fichiers externes (CSV) Ã  l'aide d'une stack moderne de **Data Engineering open-source**, dÃ©ployÃ©e localement avec **Docker**.

### ğŸ¯ Objectif du Projet :
* **IntÃ©grer des donnÃ©es transactionnelles MySQL** (donnÃ©es clients, produits, commandes).  
* **Importer des donnÃ©es externes via un fichier CSV** (localisation des magasins).  
* **Stocker les donnÃ©es dans un Data Warehouse (PostgreSQL)**.  
* **Orchestrer les flux de donnÃ©es avec Airflow**.  
* **Transformer et modÃ©liser les donnÃ©es avec dbt**.  
* **Visualiser les insights avec Apache Superset**.  
* **Documenter et gouverner les donnÃ©es avec OpenMetadata**.

---

## ğŸ¢ 2. Contexte MÃ©tier : Cas d'Usage Retail

### ğŸ“Š ScÃ©nario : Vente en ligne et magasins physiques

Une chaÃ®ne de magasins de dÃ©tail opÃ©rant Ã  la fois en ligne et en physique souhaite mieux comprendre ses ventes, ses clients et ses magasins. Pour cela, elle a besoin de :

* **DonnÃ©es transactionnelles (MySQL)** : Commandes clients en ligne (produits achetÃ©s, montants, date).  
* **DonnÃ©es externes (CSV)** : Informations gÃ©ographiques sur les magasins physiques (ville, rÃ©gion, pays).  
* **Centralisation dans un entrepÃ´t de donnÃ©es (PostgreSQL)** pour analyse et reporting.  
* **Transformations analytiques (dbt)** : ModÃ©lisation des ventes par client, produit, et localisation.  
* **Orchestration (Airflow)** : Automatisation des workflows ETL/ELT.  
* **Visualisation (Superset)** : Tableaux de bord interactifs sur les ventes et performances.

---

## ğŸ› ï¸ 3. Architecture Technique

L'architecture de RetailFlow repose sur une approche **modulaire et Ã©volutive**, comme illustrÃ©e ci-dessous :

![Architecture Diagramme](./static/projet-retailflow-talend.png)

---

## ğŸ“Œ 4. DÃ©tails des Composants :

* **MySQL (Base de donnÃ©es transactionnelle)**  
  * Stocke les transactions clients, produits et commandes.

* **Fichier CSV (Localisation des magasins)**  
  * Fichier externe stockÃ© localement.

* **Talend (Ingestion de donnÃ©es)**  
  * Collecte les donnÃ©es depuis MySQL et le fichier CSV.  
  * Envoie les donnÃ©es vers MinIO (Data Lake) et PostgreSQL (Data Warehouse).

* **MinIO (Stockage Objet)**  
  * Stockage de fichiers bruts et formatÃ©s pour les traitements futurs.

* **PostgreSQL (Data Warehouse)**  
  * Stocke les donnÃ©es modÃ©lisÃ©es pour les requÃªtes analytiques.

* **dbt (Transformation)**  
  * Transforme les donnÃ©es en modÃ¨les analytiques (vue agrÃ©gÃ©e des ventes, clients, etc.).

* **Airflow (Orchestration)**  
  * Automatisation de la collecte (Talend), transformation (dbt) et mise Ã  jour des tableaux de bord.

* **Superset (Visualisation)**  
  * CrÃ©e des tableaux de bord interactifs pour explorer les ventes, les clients et les magasins.

---

## ğŸ“ 5. Ã‰tapes ClÃ©s du Pipeline de DonnÃ©es

* **Ingestion avec Talend :**  
  * Synchronisation rÃ©guliÃ¨re des donnÃ©es depuis MySQL et le fichier CSV vers PostgreSQL et MinIO.

* **Stockage :**  
  * Les donnÃ©es sont centralisÃ©es dans PostgreSQL pour des analyses structurÃ©es.  
  * Les fichiers bruts sont stockÃ©s dans MinIO.

* **Transformation avec dbt :**  
  * AgrÃ©gation des ventes par client, produit et localisation.  
  * Nettoyage et structuration des donnÃ©es.

* **Orchestration avec Airflow :**  
  * Automatisation de la collecte (Talend), transformation (dbt) et mise Ã  jour des tableaux de bord.

* **Visualisation avec Superset :**  
  * CrÃ©ation de tableaux de bord pour analyser :  
    * Les produits les plus vendus.  
    * Les clients les plus rentables.  
    * La performance des magasins par rÃ©gion.

---

## ğŸ“ 6. Configuration du Projet

### ğŸ› ï¸ PrÃ©requis :
* Docker & Docker Compose installÃ©s localement.  
* Python 3.x pour les scripts de gÃ©nÃ©ration de donnÃ©es.

### ğŸ“¥ Installation :
```bash
git clone https://github.com/username/retail-flow-project.git
cd retail-flow-project

# Ã‰tape 1
cd step1-mysql
docker-compose up -d
python data_generator.py

# Ã‰tape 2
cd step2-data-engineering
docker-compose up -d
```


## ğŸ“Š 7. Tableaux de Bord Attendues :
* Performance des ventes par rÃ©gion.
* Top 10 des clients avec les plus gros achats.
* Produits les plus vendus.

## ğŸ“Š 8. Ressources Utiles :
* Talend Documentation: https://www.talend.com
* dbt Documentation: https://docs.getdbt.com
* Apache Superset: https://superset.apache.org

## ğŸ“‚ 9. Arborescence du Projet :
```plaintext
retail-flow-project/
â”‚
â”œâ”€ step1-mysql/
â”‚  â”œâ”€ docker-compose.yml
â”‚  â”œâ”€ init-db.sql
â”‚  â”œâ”€ data_generator.py
â”‚
â”œâ”€ step2-data-engineering/
â”‚  â”œâ”€ docker-compose.yml
â”‚  â”œâ”€ .env
â”‚  â”œâ”€ minio/              
â”‚  â”œâ”€ postgres/           
â”‚  â”œâ”€ dbt/                
â”‚  â”œâ”€ airflow/            
â”‚  â”œâ”€ superset/                
â”‚  â”œâ”€ scripts/           
â”‚  â”œâ”€ logs/               
â”‚
â”œâ”€ talend/
â”‚  â”œâ”€ jobs/ 
â”‚  â”œâ”€ configs/
â”‚
â”œâ”€ data/
â”‚  â”œâ”€ store_locations.csv
â”‚
â””â”€ README.md
```
## Licence:
<p>Ce projet est sous licence MIT. Consultez le fichier LICENSE.md pour plus de dÃ©tails.</p>

## Contact:
<p>Auteur : julien Awon'ga </p>
<p>Email : julienawon@gmail.com</p>